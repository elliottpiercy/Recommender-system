{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issues with the data handler. 2 movie ID variables\n",
    "# Create a method to output predicted movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_handler():\n",
    "    \n",
    "    def __init__(self,path):\n",
    "        self.path = path\n",
    "        \n",
    "        \n",
    "    def get_names(self):\n",
    "        \n",
    "        movie_name = np.asarray(pd.read_csv(self.path+'movies.csv')[['title']])\n",
    "#         movie_ID = np.asarray(pd.read_csv(self.path+'movies.csv')[['movieId']])\n",
    "        return movie_name\n",
    "    \n",
    "    def read_data(self,plot=False):\n",
    "\n",
    "        ratings = pd.read_csv(self.path+'ratings.csv')\n",
    "        userId = np.asarray(ratings[['userId']])\n",
    "        movieId = np.asarray(ratings[['movieId']])\n",
    "        rating = np.asarray(ratings[['rating']])\n",
    "\n",
    "\n",
    "\n",
    "        n_users = ratings.userId.unique() #find unique userId's\n",
    "        n_items = ratings.movieId.unique() #find unique movieId's\n",
    "        n_rating = ratings.rating.unique() #find number of unique ratings\n",
    "\n",
    "        keys = n_items\n",
    "        values = np.arange(len(n_items))\n",
    "        dictionary = dict(zip(keys, values)) # dictionary maps index to movieId\n",
    "        data = np.zeros((len(n_users), len(n_items))) \n",
    "        # rows correspond to userId and column correspond to movieId by the n_users and n_items arrays\n",
    "\n",
    "\n",
    "        for i in range(len(ratings)): \n",
    "            movie_loc = dictionary.get(movieId[i][0])\n",
    "            user_loc = userId[i]-1\n",
    "            loc_rating = rating[i]    \n",
    "            data[user_loc,movie_loc] = loc_rating\n",
    "\n",
    "        userId = np.arange(len(n_users))\n",
    "        np.random.seed(1)\n",
    "        np.random.shuffle(data) \n",
    "        np.random.seed(1)\n",
    "        np.random.shuffle(userId)\n",
    "\n",
    "        if plot:\n",
    "            import matplotlib.pyplot as plt;plt.rcdefaults()\n",
    "            import matplotlib.pyplot as plt\n",
    "\n",
    "            values = []\n",
    "            n_rating = np.sort(n_rating)\n",
    "            for i in range(len(n_rating)):\n",
    "                values = np.append(values,np.count_nonzero(rating == n_rating[i]))\n",
    "\n",
    "\n",
    "            plt.bar(np.arange(len(n_rating)), values, align='center', alpha=0.5)\n",
    "            plt.xticks(np.arange(len(n_rating)), n_rating, rotation='vertical')\n",
    "            plt.ylabel('No. of ratings')\n",
    "            plt.xlabel(\"Rating\")\n",
    "            plt.title('No. of each rating')\n",
    "            plt.show()\n",
    "\n",
    "        return data,movieId\n",
    "\n",
    "handler = data_handler(path = 'ml-latest-small/')\n",
    "data, array_to_ID = handler.read_data(plot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import autoencoder as model\n",
    "X_train,X_test = train_test_split(data, test_size=0.09)\n",
    "\n",
    "\n",
    "save_path = './models/'\n",
    "save_name = 'rec_system'\n",
    "\n",
    "model = model.autoencoder(batch_size = 61,\n",
    "                        num_hid1 = 256, \n",
    "                        num_hid2 = 128,\n",
    "                        activation = 'relu')\n",
    "\n",
    "\n",
    "model.fit(save_path = save_path, \n",
    "          save_name=save_name, \n",
    "          lr = 0.001, \n",
    "          epochs = 15, \n",
    "          X_train = X_train)\n",
    "\n",
    "\n",
    "error,predictions = model.predict(save_path = save_path,\n",
    "                                  save_name = save_name,\n",
    "                                  X_test = X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class returns top 3 recommendations for each user in the test data.\n",
    "class find_recommendations():\n",
    "    \n",
    "    def __init__(self,predictions,data,movie_name):\n",
    "        self.predictions = predictions\n",
    "        self.data = data\n",
    "        self.movie_name = movie_name\n",
    "        \n",
    "    def locate(self,num_recommendations):\n",
    "\n",
    "        recommendations = {}\n",
    "        \n",
    "        for user in range(len(predictions)):\n",
    "\n",
    "            rec = np.argsort(self.predictions[user])[::-1]\n",
    "            user_unseen = np.where(self.data[user]==0)[0]\n",
    "            \n",
    "            intersection = []\n",
    "            for x in rec:\n",
    "                if x in user_unseen:\n",
    "                    intersection = np.append(intersection,x)\n",
    "                if len(intersection)==num_recommendations:\n",
    "                    break\n",
    "                    \n",
    "            \n",
    "            recommendations[user] = self.movie_name[intersection.astype(int)]\n",
    "        return recommendations\n",
    "    \n",
    "movie_names = handler.get_names()    \n",
    "engine = find_recommendations(predictions,X_test,movie_names)\n",
    "recommendations = engine.locate(num_recommendations=3)\n",
    "\n",
    "print(recommendations[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaborative filtering\n",
    "\n",
    "movie_names = handler.get_names()  \n",
    "from scipy import spatial\n",
    "\n",
    "\n",
    "user_in_q = data[0]\n",
    "score = []\n",
    "for user in data:\n",
    "    score = np.append(score,spatial.distance.cosine(user_in_q, user))\n",
    "score = np.delete(score,0)\n",
    "location = np.argmax(score)\n",
    "\n",
    "\n",
    "user_unseen = np.where(user_in_q ==0)\n",
    "data_non_0s = np.where(data[np.argmax(score)]!=0)\n",
    "recommendations = np.intersect1d(user_unseen,data_non_0s)\n",
    "\n",
    "recommendations= data[location][recommendations]\n",
    "recommendations = sorted(range(len(recommendations)), key=lambda i: recommendations[i])[-3:]\n",
    "\n",
    "print(movie_names[recommendations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
